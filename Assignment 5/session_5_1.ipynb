{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b98369-c7ba-450b-a8b5-e34319000695",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Python for Data Science\n",
    "## Session 5 \n",
    "### Basic Libraries II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace1343-d73d-466d-aa07-56febbb7cbf1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ffee69-5d4d-4f1c-9ed7-083afbc931ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Outline\n",
    "\n",
    "1. Json, pickle and parquet formats\n",
    "\n",
    "2. Re library\n",
    "\n",
    "3. Time and Datetime libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba315f4-e9bf-4a66-b3d3-593037c3ca70",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed45dcb-2cf5-4bfa-ba6e-5da25c59757c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "Before starting working with different formats, let's see how we can create and read text files using Python buil-in function called **open**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ccded",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Open and write down a file\n",
    "f = open('text_file.txt', 'w')\n",
    "f.write('Hello')\n",
    "f.write('\\n')\n",
    "f.write('Bye')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116186a1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Open and read content of a file\n",
    "f = open('text_file.txt', 'r')\n",
    "content = f.read()\n",
    "f.close()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d60bcc2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We can also simply split lines by using\n",
    "f = open('text_file.txt', 'r')\n",
    "lines = f.read().splitlines()\n",
    "f.close()\n",
    "# loop over the lines\n",
    "for idx, line in enumerate(lines): # enumerate provides returns the index and element\n",
    "    print(f'Line {idx}: {line}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef202e60",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's create a CSV (comma separated values) file\n",
    "header = \"Name,Age,Grade\\n\"\n",
    "rows = [\n",
    "    \"Jaume,30,8.9\\n\",\n",
    "    \"Francisco,25,7.1\\n\",\n",
    "    \"Elena,35,9.2\\n\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4930e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"grades.csv\", \"w\") as f:\n",
    "    f.write(header) # Write the header\n",
    "    \n",
    "    # Write each row of data\n",
    "    for row in rows:\n",
    "        f.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de8a4b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"grades.csv\", \"r\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "    \n",
    "header = lines.pop(0)\n",
    "header = header.split(',')\n",
    "\n",
    "print(header)\n",
    "\n",
    "grades = {'students': []}\n",
    "# create dictionary\n",
    "for line in lines:\n",
    "    student_dict = {}\n",
    "    values = line.split(',')\n",
    "    for idx, column in enumerate(header):\n",
    "        student_dict[column] = values[idx]\n",
    "    grades['students'].append(student_dict)\n",
    "    \n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dc1a74",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "Another useful statement is **with**. It helps handling properly the resources within its reach, by closing them after its execution. It also makes the code more readable and maintainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474a10ea",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with open('text_file.txt', 'r') as f: # we don't have to close the open file, f.close()\n",
    "    lines = f.read().splitlines()\n",
    "    \n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f7645",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "JavaScript Object Notation (JSON) is a text-based format used for data storing and data interchange across different platforms and languages.\n",
    "\n",
    "Same as dictionaries, data is represented as key-value pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e215c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "JavaScript Object Notation (JSON) is a text-based format used for data storing and data interchange across different platforms and languages.\n",
    "\n",
    "Same as dictionaries, data is represented as key-value pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85baeee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "    \"students\": [\n",
    "        {\n",
    "            \"name\": \"Amelie\",\n",
    "            \"age\": 35\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Edgar\",\n",
    "            \"age\": 32\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03372288",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# other valid formats\n",
    "[\n",
    "    {\n",
    "        \"name\": \"Amelie\",\n",
    "        \"age\": 35\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Edgar\",\n",
    "        \"age\": 32\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21363512",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# other valid formats\n",
    "[\n",
    "    \"Amelie\",\n",
    "    137,\n",
    "    True, # within the json file True is equivalent to true\n",
    "    None, # within the json file None is equivalent to null\n",
    "    {\"age\": 35},\n",
    "    [10, 12, 13]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4f9fc6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "To read and write down json files and manipulate them, we have the built-in json library within Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d6310",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data = {\n",
    "    \"students\": [\n",
    "        {\n",
    "            \"name\": \"Amelie\",\n",
    "            \"age\": 35,\n",
    "            \"scolarship\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Edgar\",\n",
    "            \"age\": 32,\n",
    "            \"scolarship\": None\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('json_example.json', 'w') as f: # write down json\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6094e3cf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with open('json_example.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "    \n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ad57c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "Similar to JSON, Python includes a Pickle library. However, in contrast to the JSON format, Pickle is a Python-specific serialization format. The Pickle library provides tools to serialize Python objects, which involves transforming them into a stream of bytes. It also allows you to read these byte streams by deserializing them, transforming them back into their original Python objects.\n",
    "\n",
    "In contrast to the JSON format, the binary format is usually more compact and, therefore, more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab37f4f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.random.rand(10)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Serializing (dumping) the object\n",
    "with open('data.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "# Deserializing (loading) the object\n",
    "with open('data.pkl', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "print(loaded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502f8a2f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "**IMPORTANT**: Be extremely carefull when loading pickled data from untrusted sources. Pickles can execute arbitrary code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5826f2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "To work with **Parquet** files, you need either the **pyarrow** or **pandas** library. Parquet is a columnar storage format, meaning that each row represents a sample, and each column represents an attribute. This is a powerful format commonly used as a standard in platforms like **Hugging Face**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fce0ca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd # if it is not working, simply uncomment the following line\n",
    "# !pip install pandas\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'age': [25, 30, 35]\n",
    "})\n",
    "\n",
    "# Writing DataFrame to Parquet file with Pandas\n",
    "df.to_parquet('data.parquet')\n",
    "\n",
    "# Reading DataFrame from Parquet file with Pandas\n",
    "df_loaded = pd.read_parquet('data.parquet')\n",
    "\n",
    "print(df_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004bb3cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "When working with text, one of the most powerful tools is regular expressions, aka **regex**. With regex, you can perform complex pattern matching using wildcards and other special characters. Let's see how we could have handled session's four exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746e487",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "data = \"What a wonderful life if we could play more time.\"\n",
    "\n",
    "# Regex pattern to find 'if'\n",
    "pattern = 'if'\n",
    "\n",
    "# Search for the pattern\n",
    "matches = re.findall(pattern, data)\n",
    "\n",
    "print(matches) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1d4ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "Let's see how we could have handled session's four exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e73afc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Regex pattern, r in front of strings tell python to treat them as raw strings\n",
    "# we do this so slashes don't get interpret as scaping symbol\n",
    "pattern = r'(\\d{8})_(\\d{6})_SN(\\d+)_QUICKVIEW_VISUAL_([\\d_]+)_([A-Za-z0-9\\-_.]+)\\.txt' \n",
    "\n",
    "annotations = glob.glob('session_4/annotations/*.txt')\n",
    "\n",
    "for annotation in annotations:\n",
    "\n",
    "    # extract the file name\n",
    "    filename = os.path.basename(annotation)\n",
    "    \n",
    "    # Search and extract values\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        date, time, satellite_number, version, unique_region = match.groups()\n",
    "        print(f\"Date: {date}; Time: {time}; SN: {satellite_number}; ver: {version}; region: {unique_region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9fc572",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pattern = r'(\\d{8})_(\\d{6})_SN(\\d+)_QUICKVIEW_VISUAL_([\\d_]+)_([A-Za-z0-9\\-_.]+)\\.txt'\n",
    "\n",
    "'''\n",
    "(\\d{8}): Captures 8 digits (YYYYMMDD).\n",
    "_(\\d{6}): Captures 6 digits (HHMMSS).\n",
    "_SN(\\d+): Captures one or more digits.\n",
    "_QUICKVIEW_VISUAL_([\\d_]+): Captures digits and underscores.\n",
    "_([A-Za-z0-9\\-_.]+): Captures letters, numbers, hyphens (-), underscores (_), and dots (.).\n",
    "\\.txt: Makes sure that the filename ends with .txt.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c2d658",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "**Time** and **Datetime** are other two Python built-in libraries used in plenty of pipelines involving time measurements, timestamp creation and dates manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90b193",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d51166e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Get current timestamp\n",
    "t = time.time() \n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05bf5d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "time.sleep(1) # wait 1 second(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7f7e7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Â Formatting time, localtime where the code is run\n",
    "formatted_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) \n",
    "print(formatted_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec76a98",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# method now() gives us the current date and time\n",
    "now = datetime.now()\n",
    "print(now)\n",
    "\n",
    "# Similar to the strftime function in time, we can it from datetime\n",
    "formatted_now = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(formatted_now)\n",
    "\n",
    "# Parsing a string to a datetime object\n",
    "parsed_date = datetime.strptime(\"2024-10-17 21:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "print(parsed_date)\n",
    "\n",
    "# Adding a week using days with timedelta\n",
    "future_date = now + timedelta(days=7)\n",
    "print(future_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc567b3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "parsed_date.year, parsed_date.month, parsed_date.day, parsed_date.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc70e0c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic Libraries II\n",
    "\n",
    "Let's now try to use them to order the annotations by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5ffd12",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Regex pattern, r in front of strings tell python to treat them as raw strings\n",
    "# we do this so slashes don't get interpret as scaping symbol\n",
    "pattern = r'(\\d{8})_(\\d{6})_SN(\\d+)_QUICKVIEW_VISUAL_([\\d_]+)_([A-Za-z0-9\\-_.]+)\\.txt' \n",
    "\n",
    "annotations = glob.glob('session_4/annotations/*.txt')\n",
    "\n",
    "# let's create a dictionary where per each annotations we gather the datetime object\n",
    "ann_datetime = []\n",
    "\n",
    "for annotation in annotations:\n",
    "\n",
    "    # extract the file name\n",
    "    filename = os.path.basename(annotation)\n",
    "    \n",
    "    # Search and extract values\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        date, time, _, _, _ = match.groups()\n",
    "\n",
    "        # Put them together, e.g. \"20240101192856\"\n",
    "        datetime_str = date + time \n",
    "\n",
    "        # Parse the string into a datetime object\n",
    "        datetime_obj = datetime.strptime(datetime_str, \"%Y%m%d%H%M%S\")\n",
    "\n",
    "        # Output the datetime object\n",
    "        print(f\"Datetime Object: {datetime_obj}\")\n",
    "        \n",
    "        ann_datetime.append((filename, datetime_obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a7793",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "indices = np.argsort([date for name, date in ann_datetime])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f9ba90",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for i in indices:\n",
    "    print(ann_datetime[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012aeb1b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "\n",
    "Reusing the same annotations we work with in the previous session, answer the following items using the libraries we saw today: \n",
    "\n",
    "1. How many annotations you have per month and year. Which month has more annotation files.\n",
    "2. Create a dictionary where each **key** is a month, and the corresponding **value** is a list containing all the annotation names with where their date corresponds to the month. \n",
    "   - a. Save it following the json format, and load it again to check that everything is ok.\n",
    "   - b. Save it this time using Pickle.\n",
    "   - c. Instead of storing a list of all the annotation names happening that month, let's create for each annotation a dictionary with keys: name and date (using a datetime object).\n",
    "3. Print all the annotations from the oldest ones to the newest one during the seconf half of the 2024. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26e28b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "\n",
    "pattern = r'(\\d{8})_(\\d{6})_SN(\\d+)_QUICKVIEW_VISUAL_([\\d_]+)_([A-Za-z0-9\\-_.]+)\\.txt' \n",
    "\n",
    "annotations = glob.glob('session_4/annotations/*.txt')\n",
    "\n",
    "for annotation in annotations:\n",
    "\n",
    "    filename = os.path.basename(annotation)\n",
    "    \n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        date, time, satellite_number, version, unique_region = match.groups()\n",
    "        #print(f\"Date: {date}; Time: {time}; SN: {satellite_number}; ver: {version}; region: {unique_region}\")\n",
    "\n",
    "#2\n",
    "from datetime import datetime\n",
    "\n",
    "# Dictionary to store annotations by month with datetime objects\n",
    "annotations_by_month = defaultdict(list)\n",
    "\n",
    "annotations = glob.glob('session_4/annotations/*.txt')\n",
    "\n",
    "# Process each annotation file\n",
    "for annotation in annotations:\n",
    "    filename = os.path.basename(annotation)\n",
    "    \n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        date, time, satellite_number, version, unique_region = match.groups()\n",
    "        # Extract month (January, February, etc.)\n",
    "        month = date[4:6]  # Get the month part (MM)\n",
    "        \n",
    "        # Append the annotation name to the corresponding month list\n",
    "        annotations_by_month[month].append(filename)\n",
    "\n",
    "#Save the dictionary using Pickle\n",
    "with open('annotations_by_month.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(annotations_by_month, pickle_file)\n",
    "\n",
    "# Filter annotations from July 2024 to December 2024\n",
    "second_half_2024_annotations = []\n",
    "\n",
    "for year_month, annotations in annotations_by_month.items():\n",
    "    for annotation in annotations:\n",
    "        # Check if the date is between July and December 2024\n",
    "        if year_month >= \"202407\" and year_month <= \"202412\":\n",
    "            second_half_2024_annotations.append(annotation)\n",
    "\n",
    "# Sort annotations by date\n",
    "sorted_annotations = sorted(second_half_2024_annotations, key=lambda x: x['date'])\n",
    "\n",
    "# Print the sorted annotations\n",
    "for annotation in sorted_annotations:\n",
    "    print(f\"Name: {annotation['name']}, Date: {annotation['date'].strftime('%Y-%m-%d')}\")\n",
    " \n",
    "\n",
    "sorted_annotations\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
